{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multicut\n",
    "\n",
    "Simple example for obtaining the multicut segmentation for the dataset, we have initialized in *init*.\n",
    "\n",
    "Note that for applying the pipeline to 3d data, there need only to be a few changes:\n",
    "\n",
    "* Start from an extended 3d supervoxel oversegmentation instead of flat superpixel.\n",
    "* Set the degree of anisotropy to 1.\n",
    "* Set use_2d to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import vigra\n",
    "# rand index for evaluating the multicut score\n",
    "# (I usually use the implementation from skneuro, but don't want to depend\n",
    "# on this here, so we use the sklearn implementation)\n",
    "# note that this doesnt have an ignore label...\n",
    "from sklearn.metrics import adjusted_rand_score as rand_index\n",
    "# imports from Neurocut\n",
    "from MetaSet import MetaSet\n",
    "from MCSolver import multicut_workflow\n",
    "from ExperimentSettings import ExperimentSettings\n",
    "from Postprocessing import merge_small_segments\n",
    "\n",
    "# get the metaset from the correct cache folder\n",
    "#cache_folder = \"/path/to/cache\"\n",
    "cache_folder = \"/home/consti/Work/data_master/cache_neurocut/cache_examples\"\n",
    "meta = MetaSet(cache_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing RAG for seg_id 0\n",
      "WRITING IN  /home/consti/Work/data_master/cache_neurocut/cache_examples/dataset/rag_seg0.h5 rag\n",
      "Running multicut on dataset Weights learned on dataset\n",
      "with solver opengm_exact\n",
      "Learning random forest with 200 trees\n",
      "Computing:  edge_gt with args:\n",
      "(0,)\n",
      "Loading RAG for seg_id 0 from HDF5:\n",
      "/home/consti/Work/data_master/cache_neurocut/cache_examples/dataset/rag_seg0.h5\n",
      "rag\n",
      "Loading RAG for seg_id 0 from HDF5:\n",
      "/home/consti/Work/data_master/cache_neurocut/cache_examples/dataset/rag_seg0.h5\n",
      "rag\n",
      "Computing:  _adjacent_segments with args:\n",
      "(0,)\n",
      "Getting segments adjacent to edges from RAG:\n",
      "Loading RAG for seg_id 0 from HDF5:\n",
      "/home/consti/Work/data_master/cache_neurocut/cache_examples/dataset/rag_seg0.h5\n",
      "rag\n",
      "Writing result in  /home/consti/Work/data_master/cache_neurocut/cache_examples/dataset/_adjacent_segments_0.h5 data\n",
      "Writing result in  /home/consti/Work/data_master/cache_neurocut/cache_examples/dataset/edge_gt_0.h5 data\n",
      "Computing:  ignore2ignorers with args:\n",
      "(0,)\n",
      "Loading RAG for seg_id 0 from HDF5:\n",
      "/home/consti/Work/data_master/cache_neurocut/cache_examples/dataset/rag_seg0.h5\n",
      "rag\n",
      "Writing result in  /home/consti/Work/data_master/cache_neurocut/cache_examples/dataset/ignore2ignorers_0.h5 data\n",
      "Loading RAG for seg_id 0 from HDF5:\n",
      "/home/consti/Work/data_master/cache_neurocut/cache_examples/dataset/rag_seg0.h5\n",
      "rag\n",
      "Starting Inference\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'Multicut'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e3de807441f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m mc_nodes, mc_edges, mc_energy, t_inf = multicut_from_rf_gt(\n\u001b[0;32m     66\u001b[0m     \u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseg_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseg_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     feats, feats, mc_params)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;31m# mc_nodes = result for the segments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;31m# mc_edges = result for the edges\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/consti/software/miniconda/envs/neurocut/lib/python2.7/site-packages/neurocut-0.1-py2.7.egg/neurocut/MCSolver.pyc\u001b[0m in \u001b[0;36mmulticut_from_rf_gt\u001b[1;34m(ds_train, ds_test, seg_id_train, seg_id_test, features_train, features_test, mc_params)\u001b[0m\n\u001b[0;32m    243\u001b[0m         (mc_node, mc_edges, mc_energy, t_inf) = multicut_exact(\n\u001b[0;32m    244\u001b[0m                 \u001b[0mn_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muv_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m                 edge_energies, mc_params.verbose)\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmc_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"opengm_fusionmoves\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/consti/software/miniconda/envs/neurocut/lib/python2.7/site-packages/neurocut-0.1-py2.7.egg/neurocut/MCSolver.pyc\u001b[0m in \u001b[0;36mmulticut_exact\u001b[1;34m(n_var, uv_ids, edge_energies, verbose)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"Starting Inference\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m     \u001b[0minf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopengm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMulticut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m     \u001b[0mt_inf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[0minf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'Multicut'"
     ]
    }
   ],
   "source": [
    "# reload the dataset\n",
    "meta.load()\n",
    "ds = meta.get_dataset(\"dataset\")\n",
    "\n",
    "# id of the segmentation (== superpixels) we will calculate everything for\n",
    "# we have added only one segmentation, so we have to use 0 here\n",
    "seg_id = 0\n",
    "\n",
    "# ExperimentSettings holds all relveant options for the experiments\n",
    "# they are initialised to sensible defaults and \n",
    "# we only have to change a few\n",
    "mc_params = ExperimentSettings()\n",
    "\n",
    "# cache folder for the RF\n",
    "mc_params.set_rfcache(os.path.join(cache_folder, \"rf_cache\"))\n",
    "# train RF with 500 trees\n",
    "mc_params.set_ntrees(500)\n",
    "# degree of anisotropy for the filter calculation\n",
    "# (values bigger than 20 lead to calculation in 2d)\n",
    "# set to 1. for isotropic data (default value)\n",
    "mc_params.set_anisotropy(25.)\n",
    "# flag to indicate whether special z - edge features are computed\n",
    "# set to false for isotropic data (default value)\n",
    "mc_params.set_use2d(True)\n",
    "\n",
    "# otherwise, the default parameter should be ok\n",
    "\n",
    "# list of features taken into account\n",
    "# \"raw\" -> filters on raw data accumulated over the edges\n",
    "# \"prob\" -> filters on probability maps accumulated over the edges\n",
    "# \"reg\" -> region statistics, mapped to the edges\n",
    "# \"topo\" -> topology features for the edges\n",
    "feat_list = (\"raw\", \"prob\", \"reg\", \"topo\")\n",
    "\n",
    "# in multicut_from_rf_gt, first a rf is learned with labels from\n",
    "# groundtruth projections from the training dataset\n",
    "# then this rf is applied to the test dataset and the resulting \n",
    "# probabilites for the edges are converted to energies\n",
    "# with this energies, the multicut is solved\n",
    "\n",
    "# note that we have not done a train / test split yet,\n",
    "# so train and test are the same\n",
    "\n",
    "# first parameter is the dataset we train the rf on\n",
    "# second parameter is the dataset we run the multicut on, with weights from the rf\n",
    "# third and fourth parameter: id of segmentationf for train and test dataset\n",
    "# fifth in six: features for train and test\n",
    "# seventh: the parameter object\n",
    "mc_nodes, mc_edges, mc_energy, t_inf = multicut_workflow(\n",
    "    ds, ds,\n",
    "    seg_id, seg_id,\n",
    "    feat_list, mc_params)\n",
    "# mc_nodes = result for the segments\n",
    "# mc_edges = result for the edges\n",
    "# mc_energy = energy of the solution\n",
    "# t_inf = time the inference of the mc took\n",
    "\n",
    "# project the result back to the volume\n",
    "mc_seg = ds.project_mc_result(seg_id, mc_nodes)\n",
    "# merge small segments\n",
    "mc_seg = merge_small_segments(mc_seg, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# evaluate the result\n",
    "gt = ds.gt()\n",
    "\n",
    "# evaluation with proper skneuro randIndex\n",
    "\"\"\"\n",
    "from skneuro.learning import randIndex\n",
    "\n",
    "gt = gt.astype(np.uint32)\n",
    "mc_seg = mc_seg.astype(np.uint32)\n",
    "\n",
    "print randIndex(gt.flatten(), mc_seg.flatten(), ignoreDefaultLabel = True)\n",
    "\"\"\"\n",
    "\n",
    "ri = rand_index(gt.ravel(), mc_seg.ravel())\n",
    "print \"Multicut Segmentation has a RI of\", ri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "These numbers don't look too good, but I think this is due to the sklearn metric. Visually, the result does look good and evaluation with the RandIndex from skneuro yields a value of 0.9998."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
